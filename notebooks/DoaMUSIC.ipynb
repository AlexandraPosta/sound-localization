{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUSIC model predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "import pyroomacoustics as pra\n",
    "from pyroomacoustics.utilities import normalize\n",
    "from pyroomacoustics.transform import stft\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Label resolution of angles\n",
    "RESOLUTION = 10\n",
    "\n",
    "# Determines the overlap of samples between consecutive features\n",
    "STEP = 1024\n",
    "\n",
    "# Training rooms dimensions\n",
    "ROOMS = {\n",
    "    'small' : np.array([4, 4, 3]),\n",
    "    'medium' : np.array([6, 6, 3]),\n",
    "    'large' : np.array([8, 8, 3])\n",
    "}\n",
    "\n",
    "# Testing rooms dimensions\n",
    "TEST_ROOMS = {\n",
    "    'small' : np.array([5, 5, 2]),\n",
    "    'medium' : np.array([7, 7, 2]),\n",
    "    'large' : np.array([9, 9, 2])\n",
    "}\n",
    "\n",
    "class Path:\n",
    "    def __init__(self, name, path, max_angle):\n",
    "        self.name = name\n",
    "        self.path = path\n",
    "        self.max_angle = max_angle\n",
    "\n",
    "AUDIO_PATH = [\n",
    "    Path('full', '..\\\\data\\\\full_circle\\\\0.001', 360),\n",
    "    Path('half', '..\\\\data\\\\half_circle\\\\0.001', 180)\n",
    "]\n",
    "\n",
    "GENERATE_DATA_FOR_COMPARISON = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stft_matrix(signal, frame_size=256):    \n",
    "    # Default value for overlap\n",
    "    overlap = frame_size // 2\n",
    "    \n",
    "    # Calculate Short-time Fourier transform and return\n",
    "    observation = stft.analysis(signal, L=frame_size, hop=overlap)\n",
    "\n",
    "    # Transpose from [#freq_bins,#frames,#channels] to [#channels,#frames,#freq_bins]\n",
    "    # [250, 129, 2] -> [2, 129, 250]\n",
    "    return np.transpose(observation, axes=[2, 1, 0])\n",
    "\n",
    "\n",
    "\n",
    "def get_music_prediction(X, max_angle, room_size='small', resolution=RESOLUTION, fs=16000, frame_size=256):    \n",
    "    # Get microphone locations\n",
    "    w = ROOMS[room_size][0]\n",
    "    l = ROOMS[room_size][1]\n",
    "    h = ROOMS[room_size][2]\n",
    "    mic_pos=np.c_[[w/2+0.1, 0, 0],[w/2-0.1, 0, 0]] \n",
    "\n",
    "    # Run MUSIC (MUltiple SIgnal Classication) algorithm for DOA (direction-of-arrival)\n",
    "    doa = pra.doa.MUSIC(mic_pos, fs, nfft=frame_size, n_grid=(360 // resolution), num_src=1)\n",
    "    doa.locate_sources(X)\n",
    "    pred = doa.azimuth_recon[0] \n",
    "\n",
    "    # Account for angles from 0 to 180 only\n",
    "    if max_angle == 180:\n",
    "        if pred > np.pi:\n",
    "            pred = (2 * np.pi - pred) * 180 / np.pi\n",
    "        else:\n",
    "            pred =  pred * 180 / np.pi\n",
    "\n",
    "    if max_angle == 360:\n",
    "        spatial_resp = doa.grid.values\n",
    "        min_val = spatial_resp.min()\n",
    "        max_val = spatial_resp.max()\n",
    "        spatial_resp = (spatial_resp - min_val) / (max_val - min_val)\n",
    "        phi_plt = doa.grid.azimuth / 2\n",
    "        c_phi_plt = np.r_[phi_plt, phi_plt[0]]\n",
    "        c_dirty_img = np.r_[spatial_resp, spatial_resp[0]]\n",
    "          \n",
    "        # Find average prediction\\n\",\n",
    "        pred = np.argpartition(c_dirty_img* 10. + 1, -1)[-1:]\n",
    "        pred_angle = c_phi_plt[pred] * 360 / np.pi\n",
    "        pred = round(round(np.average(pred_angle)))\n",
    "\n",
    "    return round(pred)\n",
    "\n",
    "\n",
    "\n",
    "def get_all_predictions(resolution=RESOLUTION, audio_path=AUDIO_PATH[1]):    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    info = []\n",
    "    \n",
    "    files = [file for file in os.listdir(audio_path.path)] # if 'test' in file]\n",
    "\n",
    "    # Loop through all WAVs\n",
    "    for i, file in enumerate(files):\n",
    "        if file[-3:] != 'wav': \n",
    "            continue\n",
    "\n",
    "        path = os.path.join(audio_path.path, file)\n",
    "        fs, wav_signals = wavfile.read(path)\n",
    "        label = int(file.split('_')[2])\n",
    "        \n",
    "        # Get the file information (distance, room type, sound signal angle)\n",
    "        dist = int(file.split('_')[4])\n",
    "        room = file.split('_')[6]\n",
    "        y = [(dist, room, label)]\n",
    "        \n",
    "        # Convert the wav signal into frequency domain\n",
    "        X = compute_stft_matrix(wav_signals)\n",
    "        pred = get_music_prediction(X, audio_path.max_angle, room_size=room, resolution=resolution)\n",
    "\n",
    "        # Store actual and predicted labels\n",
    "        y_true.extend(y)\n",
    "        y_pred.append(pred) \n",
    "        print(f'File {i+1}/{len(files)}', end='\\r')\n",
    "       \n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    info = y_true[:, :-1]\n",
    "    y_true = list(y_true[:, -1].astype(int))\n",
    "    y_pred = list(np.array(y_pred).astype(int))\n",
    "    return y_true, y_pred, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 38/38\r"
     ]
    }
   ],
   "source": [
    "y_true, y_pred, info = get_all_predictions(resolution=RESOLUTION, audio_path=AUDIO_PATH[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .csv dataset used inside Comparison.ipynb\n",
    "# Apply for a single file simulations \n",
    "if GENERATE_DATA_FOR_COMPARISON:\n",
    "    df = pd.DataFrame(columns=['y_true', 'y_pred'])\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] in df['y_true'].values:\n",
    "            get_current_value = df.loc[df['y_true'] == y_true[i], 'y_pred'].values\n",
    "            df.loc[df['y_true'] == y_true[i], 'y_pred'] = np.average([get_current_value[0], y_pred[i]])\n",
    "        else: \n",
    "            df.loc[len(df)] = [y_true[i], y_pred[i]]\n",
    "    df = df.sort_values(by=['y_true'])\n",
    "    df.to_csv('../comparison/MUSIC_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_true, y_pred, class_names, font_scale=0.8):\n",
    "    # Plot the confusion matrix, use the class_names as the labels\n",
    "    # only if the 180 degree scenario is used\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')    \n",
    "    fig, ax = plt.subplots(figsize=(24, 20)) \n",
    "\n",
    "    cmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\n",
    "    sns.heatmap(cm, cmap=cmap, annot=False, linewidth=0.01, ax=ax)\n",
    "\n",
    "    plt.ylabel('Actual', fontsize=40)\n",
    "    plt.xlabel('Predicted', fontsize=40)\n",
    "    #ax.set_xticklabels(class_names, fontsize=24)\n",
    "    #ax.set_yticklabels(class_names, rotation=0, fontsize=24)\n",
    "    # use matplotlib.colorbar.Colorbar object\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=40)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def rmse(y_true, y_pred):\n",
    "    # Calculate the root mean square error\n",
    "\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    total = sum(min(abs(y_t - y_p), (180 - abs(y_t - y_p))) ** 2 for y_t, y_p in zip(y_true, y_pred))\n",
    "    rms = ((total / len(y_true)) ** 0.5)\n",
    "    \n",
    "    if type(rms) == np.ndarray:\n",
    "        rms = rms[0]\n",
    "        \n",
    "    return round(rms, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix and report accuracy\n",
    "plot_cm(y_true, y_pred, np.unique(y_true))\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {round(accuracy, 6)}')\n",
    "print(f'RMSE: {rmse(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entries_with_property(info, prop, value):\n",
    "    if prop == 'distance': i = 0\n",
    "    elif prop == 'room': i = 1\n",
    "        \n",
    "    info = info[:, i]\n",
    "    return np.where(info == value)\n",
    "\n",
    "# Evaluate performance for different properties\n",
    "print('Room sizes')\n",
    "for room in ROOMS:\n",
    "    indices = get_entries_with_property(info, 'room', room)\n",
    "    y_true_room, y_pred_room = np.take(y_true, indices)[0], np.take(y_pred, indices)[0]\n",
    "    accuracy = accuracy_score(y_true_room, y_pred_room)\n",
    "    print(f\"- {room} room accuracy: {round(accuracy, 3)}\")\n",
    "    \n",
    "print('\\nDistances')\n",
    "for dist in np.unique(info[:, 0]):\n",
    "    indices = get_entries_with_property(info, 'distance', dist)\n",
    "    y_true_dist, y_pred_dist = np.take(y_true, indices)[0], np.take(y_pred, indices)[0]\n",
    "    accuracy = accuracy_score(y_true_dist, y_pred_dist)\n",
    "    print(f\"- {dist} cm distance accuracy: {round(accuracy, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
