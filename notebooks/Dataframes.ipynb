{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate .csv files for CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Label resolution of angles\n",
    "RESOLUTION = 10\n",
    "\n",
    "# Number of samples to include while creating one ML feature\n",
    "# having a sampling power that is a power of two makes the fourier\n",
    "# conversion faster if it includes a power of 2\n",
    "# duration_frame = (1/sample_rate) * frame_size = 128ms frames (10ms humn hearing resolution)\n",
    "# sample rate = 16KHz and frame_size=sample = 2048\n",
    "SAMPLES = 2048\n",
    "\n",
    "# Determines the overlap of samples between consecutive features\n",
    "STEP = 1024\n",
    "\n",
    "# Training rooms dimensions\n",
    "ROOMS = {\n",
    "    'small' : np.array([4, 4, 3]),\n",
    "    'medium' : np.array([6, 6, 3]),\n",
    "    'large' : np.array([8, 8, 3])\n",
    "}\n",
    "\n",
    "# Testing rooms dimensions\n",
    "TEST_ROOMS = {\n",
    "    'small' : np.array([5, 5, 2]),\n",
    "    'medium' : np.array([7, 7, 2]),\n",
    "    'large' : np.array([9, 9, 2])\n",
    "}\n",
    "\n",
    "AUDIO_PATH = '..\\\\data\\\\half_circle\\\\0.001\\\\'\n",
    "\n",
    "# Number of microphones\n",
    "MICS_NUMBER = 2\n",
    "MIC_COMBS = len(list(combinations(range(MICS_NUMBER), 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcc_phat(x_1, x_2, FS=16000, interp=1):    \n",
    "    n = len(x_1) + len(x_2) - 1\n",
    "    n += 1 if n % 2 else 0\n",
    "    \n",
    "    # Fourier transforms of the two signals\n",
    "    X_1 = np.fft.rfft(x_1, n=n)\n",
    "    X_2 = np.fft.rfft(x_2, n=n)\n",
    "    \n",
    "    # Normalize by the magnitude of FFT - because PHAT\n",
    "    np.divide(X_1, np.abs(X_1), X_1, where=np.abs(X_1) != 0)\n",
    "    np.divide(X_2, np.abs(X_2), X_2, where=np.abs(X_2) != 0)\n",
    "    \n",
    "    # GCC-PHAT = [X_1(f)X_2*(f)] / |X_1(f)X_2*(f)|\n",
    "    # See Knapp and Carter (1976) for reference\n",
    "    CC = X_1 * np.conj(X_2)\n",
    "    cc = np.fft.irfft(CC, n=n * interp)\n",
    "        \n",
    "    # Maximum delay between a pair of microphones,\n",
    "    # expressed in a number of samples.\n",
    "    # 0.2 m is the distance between the micropones and \n",
    "    # 340 m/s is assumed to be the speed of sound.\n",
    "    max_len = math.ceil(0.2 / 340 * FS * interp)\n",
    "    \n",
    "    # Trim the cc vector to only include a \n",
    "    # small number of samples around the origin\n",
    "    cc = np.concatenate((cc[-max_len:], cc[:max_len+1]))\n",
    "    \n",
    "    # Return the cross correlation\n",
    "    return cc\n",
    "\n",
    "\n",
    "def compute_gcc_matrix(observation, fs, interp=1):    \n",
    "    # Initialize a transformed observation, that will be populated with GCC vectors\n",
    "    # of the observation\n",
    "    transformed_observation = []\n",
    "\n",
    "    # Compute GCC for every pair of microphones\n",
    "    mic_1, mic_2 = [0, 1]\n",
    "    x_1 = observation[:, mic_1]\n",
    "    x_2 = observation[:, mic_2]\n",
    "\n",
    "    gcc = gcc_phat(x_1, x_2, FS=fs, interp=interp)\n",
    "\n",
    "    # Add the GCC vector to the GCC matrix\n",
    "    transformed_observation.append(gcc)    \n",
    "        \n",
    "    return transformed_observation\n",
    "\n",
    "\n",
    "\n",
    "def create_observations(wav_signals, fs, label, samples=1, step=1, resolution=RESOLUTION, interp=1):\n",
    "    # Lists of observations and labels that will be populated\n",
    "    X = []\n",
    "    y = []\n",
    "    rounded_label = round(label / resolution) * resolution\n",
    "    if rounded_label == 360: rounded_label = 0\n",
    "    \n",
    "    # Loop through the signal frame and take subframes\n",
    "    for i in range(0, len(wav_signals) - samples + 1, step):\n",
    "        y.append(rounded_label)\n",
    "        \n",
    "        # Extract the observation from subframe\n",
    "        observation = np.array(wav_signals[i : i + samples])\n",
    "              \n",
    "        # Transform observation into a GCC matrix\n",
    "        transformed_observation = compute_gcc_matrix(observation, fs, interp=interp)\n",
    "        X.append(transformed_observation)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def create_dataframe(subset, samples=20, step=5, resolution=RESOLUTION, interp=1):\n",
    "    dataframes = []\n",
    "    files = [f for f in os.listdir(AUDIO_PATH) if os.path.isfile(os.path.join(AUDIO_PATH, f)) and subset in f]\n",
    "\n",
    "    # Loop through all WAVs\n",
    "    for i, file in enumerate(files):\n",
    "        if file[-3:] != 'wav':\n",
    "            continue\n",
    "    \n",
    "        print(f'{subset} file {i+1}/{len(files)}', end='\\r')\n",
    "        \n",
    "        path = os.path.join(AUDIO_PATH, file)\n",
    "        fs, wav_signals = wavfile.read(path)\n",
    "\n",
    "        label = int(file.split('_')[2])\n",
    "\n",
    "        # Create observations from a given WAV file\n",
    "        X_temp, y_temp = create_observations(wav_signals, fs, label, samples, step, resolution, interp=interp)\n",
    "\n",
    "        cols = [\n",
    "                f'mics{mic_1+1}{mic_2+1}_{i}' \n",
    "                    for mic_1, mic_2 in combinations(range(MICS_NUMBER), r=2) \n",
    "                        for i in range(np.shape(X_temp)[2])\n",
    "            ]\n",
    "\n",
    "        df = pd.DataFrame(data=np.reshape(X_temp, (len(X_temp), -1)), columns=cols)\n",
    "        dist = int(file.split('_')[4])\n",
    "        room = file.split('_')[6]\n",
    "        df['dist'], df['room'] = dist, room\n",
    "            \n",
    "        # Add label column\n",
    "        df['label'] = y_temp\n",
    "        dataframes.append(df)\n",
    "        \n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encode(encoder, y_train, y_test):    \n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "    \n",
    "    # One-hot encode training and testing labels\n",
    "    enc = encoder.fit(y_train)\n",
    "    y_train = enc.transform(y_train)\n",
    "    y_test = enc.transform(y_test)\n",
    "    \n",
    "    return y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "def create_whole_dataset(df_train, df_test, encoder):\n",
    "    # Creates an entire dataset by extracting values from train and tests dataframes.\n",
    "    # One-hot encodes the labels before returning.\n",
    "    \n",
    "    # Create train/test observations\n",
    "    X_train = df_train.drop(columns=['dist', 'room', 'label']).values\n",
    "    X_test = df_test.drop(columns=['dist', 'room', 'label']).values\n",
    "    \n",
    "    # Create train/test labels\n",
    "    y_train, y_test = one_hot_encode(\n",
    "        encoder, df_train['label'].values, df_test['label'].values)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframes for Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsets csv generated!\n",
      "(57593, 21) (2166, 21) (57593, 19) (2166, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mics12_0</th>\n",
       "      <th>mics12_1</th>\n",
       "      <th>mics12_2</th>\n",
       "      <th>mics12_3</th>\n",
       "      <th>mics12_4</th>\n",
       "      <th>mics12_5</th>\n",
       "      <th>mics12_6</th>\n",
       "      <th>...</th>\n",
       "      <th>mics12_17</th>\n",
       "      <th>mics12_18</th>\n",
       "      <th>mics12_19</th>\n",
       "      <th>mics12_20</th>\n",
       "      <th>dist</th>\n",
       "      <th>room</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036792</td>\n",
       "      <td>0.058609</td>\n",
       "      <td>0.045760</td>\n",
       "      <td>0.024997</td>\n",
       "      <td>-0.006422</td>\n",
       "      <td>0.051311</td>\n",
       "      <td>0.058871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003219</td>\n",
       "      <td>-0.025594</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067049</td>\n",
       "      <td>0.084604</td>\n",
       "      <td>0.015191</td>\n",
       "      <td>0.068866</td>\n",
       "      <td>0.054778</td>\n",
       "      <td>0.058599</td>\n",
       "      <td>0.082622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016914</td>\n",
       "      <td>-0.031431</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>-0.067137</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.126132</td>\n",
       "      <td>0.224345</td>\n",
       "      <td>0.046403</td>\n",
       "      <td>0.028237</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>0.072457</td>\n",
       "      <td>0.125366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027638</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>0.046008</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175253</td>\n",
       "      <td>0.254358</td>\n",
       "      <td>-0.059829</td>\n",
       "      <td>-0.002593</td>\n",
       "      <td>-0.039549</td>\n",
       "      <td>0.019071</td>\n",
       "      <td>0.220031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024368</td>\n",
       "      <td>-0.033831</td>\n",
       "      <td>-0.009055</td>\n",
       "      <td>-0.010241</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150964</td>\n",
       "      <td>0.253522</td>\n",
       "      <td>-0.054768</td>\n",
       "      <td>0.052430</td>\n",
       "      <td>-0.018582</td>\n",
       "      <td>0.051489</td>\n",
       "      <td>0.198520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>0.020387</td>\n",
       "      <td>0.036529</td>\n",
       "      <td>0.031182</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mics12_0  mics12_1  mics12_2  mics12_3  mics12_4  mics12_5  mics12_6  ...  \\\n",
       "0  0.036792  0.058609  0.045760  0.024997 -0.006422  0.051311  0.058871  ...   \n",
       "1  0.067049  0.084604  0.015191  0.068866  0.054778  0.058599  0.082622  ...   \n",
       "2  0.126132  0.224345  0.046403  0.028237  0.021040  0.072457  0.125366  ...   \n",
       "3  0.175253  0.254358 -0.059829 -0.002593 -0.039549  0.019071  0.220031  ...   \n",
       "4  0.150964  0.253522 -0.054768  0.052430 -0.018582  0.051489  0.198520  ...   \n",
       "\n",
       "   mics12_17  mics12_18  mics12_19  mics12_20  dist   room  label  \n",
       "0  -0.003219  -0.025594   0.003241   0.000271   100  large      0  \n",
       "1  -0.016914  -0.031431   0.002551  -0.067137   100  large      0  \n",
       "2   0.027638   0.018940   0.046008   0.001600   100  large      0  \n",
       "3  -0.024368  -0.033831  -0.009055  -0.010241   100  large      0  \n",
       "4   0.008534   0.020387   0.036529   0.031182   100  large      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_dataframe('train', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "df_validation = create_dataframe('validation', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "df_test = create_dataframe('test', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "\n",
    "df_train.to_csv('../training_data/azimuth_train_dataset.csv')\n",
    "df_validation.to_csv('../training_data/azimuth_validation_dataset.csv')\n",
    "df_test.to_csv('../training_data/azimuth_test_dataset.csv')\n",
    "print('Subsets csv generated!')\n",
    "\n",
    "# Create numpy arrays with observations and one-hot labels\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "pd.set_option('display.max_columns', 15)\n",
    "df_train.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
