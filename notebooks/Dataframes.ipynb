{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate .csv files for CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Label resolution of angles\n",
    "RESOLUTION = 10\n",
    "\n",
    "# Number of samples to include while creating one ML feature\n",
    "# having a sampling power that is a power of two makes the fourier\n",
    "# conversion faster if it includes a power of 2\n",
    "# duration_frame = (1/sample_rate) * frame_size = 128ms frames (10ms humn hearing resolution)\n",
    "# sample rate = 16KHz and frame_size=sample = 2048\n",
    "SAMPLES = 2048\n",
    "\n",
    "# Determines the overlap of samples between consecutive features\n",
    "STEP = 1024\n",
    "\n",
    "# Training rooms dimensions\n",
    "ROOMS = {\n",
    "    'small' : np.array([4, 4, 3]),\n",
    "    'medium' : np.array([6, 6, 3]),\n",
    "    'large' : np.array([8, 8, 3])\n",
    "}\n",
    "\n",
    "# Testing rooms dimensions\n",
    "TEST_ROOMS = {\n",
    "    'small' : np.array([5, 5, 2]),\n",
    "    'medium' : np.array([7, 7, 2]),\n",
    "    'large' : np.array([9, 9, 2])\n",
    "}\n",
    "\n",
    "AUDIO_PATH = '..\\\\data\\\\half_circle\\\\0.001\\\\'\n",
    "\n",
    "# Number of microphones\n",
    "MICS_NUMBER = 2\n",
    "MIC_COMBS = len(list(combinations(range(MICS_NUMBER), 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcc_phat(x_1, x_2, FS=16000, interp=1):    \n",
    "    n = len(x_1) + len(x_2) - 1\n",
    "    n += 1 if n % 2 else 0\n",
    "    \n",
    "    # Fourier transforms of the two signals\n",
    "    X_1 = np.fft.rfft(x_1, n=n)\n",
    "    X_2 = np.fft.rfft(x_2, n=n)\n",
    "    \n",
    "    # Normalize by the magnitude of FFT - because PHAT\n",
    "    np.divide(X_1, np.abs(X_1), X_1, where=np.abs(X_1) != 0)\n",
    "    np.divide(X_2, np.abs(X_2), X_2, where=np.abs(X_2) != 0)\n",
    "    \n",
    "    # GCC-PHAT = [X_1(f)X_2*(f)] / |X_1(f)X_2*(f)|\n",
    "    # See Knapp and Carter (1976) for reference\n",
    "    CC = X_1 * np.conj(X_2)\n",
    "    cc = np.fft.irfft(CC, n=n * interp)\n",
    "        \n",
    "    # Maximum delay between a pair of microphones,\n",
    "    # expressed in a number of samples.\n",
    "    # 0.2 m is the distance between the micropones and \n",
    "    # 340 m/s is assumed to be the speed of sound.\n",
    "    max_len = math.ceil(0.2 / 340 * FS * interp)\n",
    "    \n",
    "    # Trim the cc vector to only include a \n",
    "    # small number of samples around the origin\n",
    "    cc = np.concatenate((cc[-max_len:], cc[:max_len+1]))\n",
    "    \n",
    "    # Return the cross correlation\n",
    "    return cc\n",
    "\n",
    "\n",
    "def compute_gcc_matrix(observation, fs, interp=1):    \n",
    "    # Initialize a transformed observation, that will be populated with GCC vectors\n",
    "    # of the observation\n",
    "    transformed_observation = []\n",
    "\n",
    "    # Compute GCC for every pair of microphones\n",
    "    mic_1, mic_2 = [0, 1]\n",
    "    x_1 = observation[:, mic_1]\n",
    "    x_2 = observation[:, mic_2]\n",
    "\n",
    "    gcc = gcc_phat(x_1, x_2, FS=fs, interp=interp)\n",
    "\n",
    "    # Add the GCC vector to the GCC matrix\n",
    "    transformed_observation.append(gcc)    \n",
    "        \n",
    "    return transformed_observation\n",
    "\n",
    "\n",
    "\n",
    "def create_observations(wav_signals, fs, label, samples=1, step=1, resolution=RESOLUTION, interp=1):\n",
    "    # Lists of observations and labels that will be populated\n",
    "    X = []\n",
    "    y = []\n",
    "    rounded_label = round(label / resolution) * resolution\n",
    "    if rounded_label == 360: rounded_label = 0\n",
    "    \n",
    "    # Loop through the signal frame and take subframes\n",
    "    for i in range(0, len(wav_signals) - samples + 1, step):\n",
    "        y.append(rounded_label)\n",
    "        \n",
    "        # Extract the observation from subframe\n",
    "        observation = np.array(wav_signals[i : i + samples])\n",
    "              \n",
    "        # Transform observation into a GCC matrix\n",
    "        transformed_observation = compute_gcc_matrix(observation, fs, interp=interp)\n",
    "        X.append(transformed_observation)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def create_dataframe(subset, samples=20, step=5, resolution=RESOLUTION, interp=1):\n",
    "    dataframes = []\n",
    "    files = [f for f in os.listdir(AUDIO_PATH) if os.path.isfile(os.path.join(AUDIO_PATH, f)) and subset in f]\n",
    "\n",
    "    # Loop through all WAVs\n",
    "    for i, file in enumerate(files):\n",
    "        if file[-3:] != 'wav':\n",
    "            continue\n",
    "    \n",
    "        print(f'{subset} file {i+1}/{len(files)}', end='\\r')\n",
    "        \n",
    "        path = os.path.join(AUDIO_PATH, file)\n",
    "        fs, wav_signals = wavfile.read(path)\n",
    "\n",
    "        label = int(file.split('_')[2])\n",
    "\n",
    "        # Create observations from a given WAV file\n",
    "        X_temp, y_temp = create_observations(wav_signals, fs, label, samples, step, resolution, interp=interp)\n",
    "\n",
    "        cols = [\n",
    "                f'mics{mic_1+1}{mic_2+1}_{i}' \n",
    "                    for mic_1, mic_2 in combinations(range(MICS_NUMBER), r=2) \n",
    "                        for i in range(np.shape(X_temp)[2])\n",
    "            ]\n",
    "\n",
    "        df = pd.DataFrame(data=np.reshape(X_temp, (len(X_temp), -1)), columns=cols)\n",
    "        dist = int(file.split('_')[4])\n",
    "        room = file.split('_')[6]\n",
    "        df['dist'], df['room'] = dist, room\n",
    "            \n",
    "        # Add label column\n",
    "        df['label'] = y_temp\n",
    "        dataframes.append(df)\n",
    "        \n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encode(encoder, y_train, y_test):    \n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "    \n",
    "    # One-hot encode training and testing labels\n",
    "    enc = encoder.fit(y_train)\n",
    "    y_train = enc.transform(y_train)\n",
    "    y_test = enc.transform(y_test)\n",
    "    \n",
    "    return y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "def create_whole_dataset(df_train, df_test, encoder):\n",
    "    \"\"\"\n",
    "    Creates an entire dataset by extracting values from train and tests dataframes.\n",
    "    One-hot encodes the labels before returning.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create train/test observations\n",
    "    X_train = df_train.drop(columns=['dist', 'room', 'label']).values\n",
    "    X_test = df_test.drop(columns=['dist', 'room', 'label']).values\n",
    "    \n",
    "    # Create train/test labels\n",
    "    y_train, y_test = one_hot_encode(\n",
    "        encoder, df_train['label'].values, df_test['label'].values)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframes for Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train file 62/1140\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_train \u001b[39m=\u001b[39m create_dataframe(\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, samples\u001b[39m=\u001b[39;49mSAMPLES, step\u001b[39m=\u001b[39;49mSTEP, resolution\u001b[39m=\u001b[39;49mRESOLUTION)\n\u001b[0;32m      2\u001b[0m df_validation \u001b[39m=\u001b[39m create_dataframe(\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m, samples\u001b[39m=\u001b[39mSAMPLES, step\u001b[39m=\u001b[39mSTEP, resolution\u001b[39m=\u001b[39mRESOLUTION)\n\u001b[0;32m      3\u001b[0m df_test \u001b[39m=\u001b[39m create_dataframe(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, samples\u001b[39m=\u001b[39mSAMPLES, step\u001b[39m=\u001b[39mSTEP, resolution\u001b[39m=\u001b[39mRESOLUTION)\n",
      "Cell \u001b[1;32mIn[2], line 90\u001b[0m, in \u001b[0;36mcreate_dataframe\u001b[1;34m(subset, samples, step, resolution, interp)\u001b[0m\n\u001b[0;32m     87\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(file\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m2\u001b[39m])\n\u001b[0;32m     89\u001b[0m \u001b[39m# Create observations from a given WAV file\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m X_temp, y_temp \u001b[39m=\u001b[39m create_observations(wav_signals, fs, label, samples, step, resolution, interp\u001b[39m=\u001b[39;49minterp)\n\u001b[0;32m     92\u001b[0m cols \u001b[39m=\u001b[39m [\n\u001b[0;32m     93\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmics\u001b[39m\u001b[39m{\u001b[39;00mmic_1\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mmic_2\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \n\u001b[0;32m     94\u001b[0m             \u001b[39mfor\u001b[39;00m mic_1, mic_2 \u001b[39min\u001b[39;00m combinations(\u001b[39mrange\u001b[39m(MICS_NUMBER), r\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m) \n\u001b[0;32m     95\u001b[0m                 \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(np\u001b[39m.\u001b[39mshape(X_temp)[\u001b[39m2\u001b[39m])\n\u001b[0;32m     96\u001b[0m     ]\n\u001b[0;32m     98\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mreshape(X_temp, (\u001b[39mlen\u001b[39m(X_temp), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)), columns\u001b[39m=\u001b[39mcols)\n",
      "Cell \u001b[1;32mIn[2], line 66\u001b[0m, in \u001b[0;36mcreate_observations\u001b[1;34m(wav_signals, fs, label, samples, step, resolution, interp)\u001b[0m\n\u001b[0;32m     63\u001b[0m     observation \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(wav_signals[i : i \u001b[39m+\u001b[39m samples])\n\u001b[0;32m     65\u001b[0m     \u001b[39m# Transform observation into a GCC matrix\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     transformed_observation \u001b[39m=\u001b[39m compute_gcc_matrix(observation, fs, interp\u001b[39m=\u001b[39;49minterp)\n\u001b[0;32m     67\u001b[0m     X\u001b[39m.\u001b[39mappend(transformed_observation)\n\u001b[0;32m     69\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "Cell \u001b[1;32mIn[2], line 42\u001b[0m, in \u001b[0;36mcompute_gcc_matrix\u001b[1;34m(observation, fs, interp)\u001b[0m\n\u001b[0;32m     39\u001b[0m x_1 \u001b[39m=\u001b[39m observation[:, mic_1]\n\u001b[0;32m     40\u001b[0m x_2 \u001b[39m=\u001b[39m observation[:, mic_2]\n\u001b[1;32m---> 42\u001b[0m gcc \u001b[39m=\u001b[39m gcc_phat(x_1, x_2, FS\u001b[39m=\u001b[39;49mfs, interp\u001b[39m=\u001b[39;49minterp)\n\u001b[0;32m     44\u001b[0m \u001b[39m# Add the GCC vector to the GCC matrix\u001b[39;00m\n\u001b[0;32m     45\u001b[0m transformed_observation\u001b[39m.\u001b[39mappend(gcc)    \n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mgcc_phat\u001b[1;34m(x_1, x_2, FS, interp)\u001b[0m\n\u001b[0;32m      3\u001b[0m n \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m n \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Fourier transforms of the two signals\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m X_1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfft\u001b[39m.\u001b[39;49mrfft(x_1, n\u001b[39m=\u001b[39;49mn)\n\u001b[0;32m      7\u001b[0m X_2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfft\u001b[39m.\u001b[39mrfft(x_2, n\u001b[39m=\u001b[39mn)\n\u001b[0;32m      9\u001b[0m \u001b[39m# Normalize by the magnitude of FFT - because PHAT\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mrfft\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\fft\\_pocketfft.py:409\u001b[0m, in \u001b[0;36mrfft\u001b[1;34m(a, n, axis, norm)\u001b[0m\n\u001b[0;32m    407\u001b[0m     n \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mshape[axis]\n\u001b[0;32m    408\u001b[0m inv_norm \u001b[39m=\u001b[39m _get_forward_norm(n, norm)\n\u001b[1;32m--> 409\u001b[0m output \u001b[39m=\u001b[39m _raw_fft(a, n, axis, \u001b[39mTrue\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, inv_norm)\n\u001b[0;32m    410\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\fft\\_pocketfft.py:70\u001b[0m, in \u001b[0;36m_raw_fft\u001b[1;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[0;32m     67\u001b[0m         a \u001b[39m=\u001b[39m z\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m a\u001b[39m.\u001b[39mndim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m     r \u001b[39m=\u001b[39m pfi\u001b[39m.\u001b[39;49mexecute(a, is_real, is_forward, fct)\n\u001b[0;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     a \u001b[39m=\u001b[39m swapaxes(a, axis, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_train = create_dataframe('train', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "df_validation = create_dataframe('validation', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "df_test = create_dataframe('test', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "\n",
    "df_train.to_csv('../training_data/azimuth_train_dataset.csv')\n",
    "df_validation.to_csv('../training_data/azimuth_validation_dataset.csv')\n",
    "df_test.to_csv('../training_data/azimuth_test_dataset.csv')\n",
    "print('Subsets csv generated!')\n",
    "\n",
    "# Create numpy arrays with observations and one-hot labels\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "pd.set_option('display.max_columns', 15)\n",
    "df_train.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
