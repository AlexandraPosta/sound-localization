{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate .csv files for CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Label resolution of angles\n",
    "RESOLUTION = 10\n",
    "\n",
    "# Number of samples to include while creating one ML feature\n",
    "# having a sampling power that is a power of two makes the fourier\n",
    "# conversion faster if it includes a power of 2\n",
    "# duration_frame = (1/sample_rate) * frame_size = 128ms frames (10ms humn hearing resolution)\n",
    "# sample rate = 16KHz and frame_size=sample = 2048\n",
    "SAMPLES = 2048\n",
    "\n",
    "# Determines the overlap of samples between consecutive features\n",
    "STEP = 1024\n",
    "\n",
    "# Training rooms dimensions\n",
    "ROOMS = {\n",
    "    'small' : np.array([4, 4, 3]),\n",
    "    'medium' : np.array([6, 6, 3]),\n",
    "    'large' : np.array([8, 8, 3])\n",
    "}\n",
    "\n",
    "# Testing rooms dimensions\n",
    "TEST_ROOMS = {\n",
    "    'small' : np.array([5, 5, 2]),\n",
    "    'medium' : np.array([7, 7, 2]),\n",
    "    'large' : np.array([9, 9, 2])\n",
    "}\n",
    "\n",
    "AUDIO_PATH = 'C:\\\\Users\\\\Alex\\\\source\\\\repos\\\\sound-localization\\\\data\\\\full_circle\\\\0.001\\\\'\n",
    "\n",
    "'''\n",
    "AUDIO_PATH = [\n",
    "    Path('full', 'C:\\\\Users\\\\Alex\\\\source\\\\repos\\\\sound-localization\\\\data\\\\full_circle', 360),\n",
    "    Path('half', 'C:\\\\Users\\\\Alex\\\\source\\\\repos\\\\sound-localization\\\\data\\\\half_circle', 180)\n",
    "]\n",
    "'''\n",
    "\n",
    "# Number of microphones\n",
    "MICS_NUMBER = 2\n",
    "MIC_COMBS = len(list(combinations(range(MICS_NUMBER), 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcc_phat(x_1, x_2, FS=16000, interp=1):    \n",
    "    n = len(x_1) + len(x_2) - 1\n",
    "    n += 1 if n % 2 else 0\n",
    "    \n",
    "    # Fourier transforms of the two signals\n",
    "    X_1 = np.fft.rfft(x_1, n=n)\n",
    "    X_2 = np.fft.rfft(x_2, n=n)\n",
    "    \n",
    "    # Normalize by the magnitude of FFT - because PHAT\n",
    "    np.divide(X_1, np.abs(X_1), X_1, where=np.abs(X_1) != 0)\n",
    "    np.divide(X_2, np.abs(X_2), X_2, where=np.abs(X_2) != 0)\n",
    "    \n",
    "    # GCC-PHAT = [X_1(f)X_2*(f)] / |X_1(f)X_2*(f)|\n",
    "    # See Knapp and Carter (1976) for reference\n",
    "    CC = X_1 * np.conj(X_2)\n",
    "    cc = np.fft.irfft(CC, n=n * interp)\n",
    "        \n",
    "    # Maximum delay between a pair of microphones,\n",
    "    # expressed in a number of samples.\n",
    "    # 0.2 m is the distance between the micropones and \n",
    "    # 340 m/s is assumed to be the speed of sound.\n",
    "    max_len = math.ceil(0.2 / 340 * FS * interp)\n",
    "    \n",
    "    # Trim the cc vector to only include a \n",
    "    # small number of samples around the origin\n",
    "    cc = np.concatenate((cc[-max_len:], cc[:max_len+1]))\n",
    "    \n",
    "    # Return the cross correlation\n",
    "    return cc\n",
    "\n",
    "\n",
    "def compute_gcc_matrix(observation, fs, interp=1):    \n",
    "    # Initialize a transformed observation, that will be populated with GCC vectors\n",
    "    # of the observation\n",
    "    transformed_observation = []\n",
    "\n",
    "    # Compute GCC for every pair of microphones\n",
    "    mic_1, mic_2 = [0, 1]\n",
    "    x_1 = observation[:, mic_1]\n",
    "    x_2 = observation[:, mic_2]\n",
    "\n",
    "    gcc = gcc_phat(x_1, x_2, FS=fs, interp=interp)\n",
    "\n",
    "    # Add the GCC vector to the GCC matrix\n",
    "    transformed_observation.append(gcc)    \n",
    "        \n",
    "    return transformed_observation\n",
    "\n",
    "\n",
    "\n",
    "def create_observations(wav_signals, fs, label, samples=1, step=1, resolution=RESOLUTION, interp=1):\n",
    "    # Lists of observations and labels that will be populated\n",
    "    X = []\n",
    "    y = []\n",
    "    rounded_label = round(label / resolution) * resolution\n",
    "    if rounded_label == 360: rounded_label = 0\n",
    "    \n",
    "    # Loop through the signal frame and take subframes\n",
    "    for i in range(0, len(wav_signals) - samples + 1, step):\n",
    "        y.append(rounded_label)\n",
    "        \n",
    "        # Extract the observation from subframe\n",
    "        observation = np.array(wav_signals[i : i + samples])\n",
    "              \n",
    "        # Transform observation into a GCC matrix\n",
    "        transformed_observation = compute_gcc_matrix(observation, fs, interp=interp)\n",
    "        X.append(transformed_observation)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def create_dataframe(subset, samples=20, step=5, resolution=RESOLUTION, interp=1):\n",
    "    dataframes = []\n",
    "    files = [f for f in os.listdir(AUDIO_PATH) if os.path.isfile(os.path.join(AUDIO_PATH, f)) and subset in f]\n",
    "\n",
    "    # Loop through all WAVs\n",
    "    for i, file in enumerate(files):\n",
    "        if file[-3:] != 'wav':\n",
    "            continue\n",
    "    \n",
    "        print(f'{subset} file {i+1}/{len(files)}', end='\\r')\n",
    "        \n",
    "        path = os.path.join(AUDIO_PATH, file)\n",
    "        fs, wav_signals = wavfile.read(path)\n",
    "\n",
    "        label = int(file.split('_')[2])\n",
    "\n",
    "        # Create observations from a given WAV file\n",
    "        X_temp, y_temp = create_observations(wav_signals, fs, label, samples, step, resolution, interp=interp)\n",
    "\n",
    "        cols = [\n",
    "                f'mics{mic_1+1}{mic_2+1}_{i}' \n",
    "                    for mic_1, mic_2 in combinations(range(MICS_NUMBER), r=2) \n",
    "                        for i in range(np.shape(X_temp)[2])\n",
    "            ]\n",
    "\n",
    "        df = pd.DataFrame(data=np.reshape(X_temp, (len(X_temp), -1)), columns=cols)\n",
    "        dist = int(file.split('_')[4])\n",
    "        room = file.split('_')[6]\n",
    "        df['dist'], df['room'] = dist, room\n",
    "            \n",
    "        # Add label column\n",
    "        df['label'] = y_temp\n",
    "        dataframes.append(df)\n",
    "        \n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encode(encoder, y_train, y_test):    \n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "    \n",
    "    # One-hot encode training and testing labels\n",
    "    enc = encoder.fit(y_train)\n",
    "    y_train = enc.transform(y_train)\n",
    "    y_test = enc.transform(y_test)\n",
    "    \n",
    "    return y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "def create_whole_dataset(df_train, df_test, encoder):\n",
    "    \"\"\"\n",
    "    Creates an entire dataset by extracting values from train and tests dataframes.\n",
    "    One-hot encodes the labels before returning.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create train/test observations\n",
    "    X_train = df_train.drop(columns=['dist', 'room', 'label']).values\n",
    "    X_test = df_test.drop(columns=['dist', 'room', 'label']).values\n",
    "    \n",
    "    # Create train/test labels\n",
    "    y_train, y_test = one_hot_encode(\n",
    "        encoder, df_train['label'].values, df_test['label'].values)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframes for Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsets csv generated!\n",
      "(57593, 21) (2166, 21) (57593, 19) (2166, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mics12_0</th>\n",
       "      <th>mics12_1</th>\n",
       "      <th>mics12_2</th>\n",
       "      <th>mics12_3</th>\n",
       "      <th>mics12_4</th>\n",
       "      <th>mics12_5</th>\n",
       "      <th>mics12_6</th>\n",
       "      <th>...</th>\n",
       "      <th>mics12_17</th>\n",
       "      <th>mics12_18</th>\n",
       "      <th>mics12_19</th>\n",
       "      <th>mics12_20</th>\n",
       "      <th>dist</th>\n",
       "      <th>room</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016540</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.065406</td>\n",
       "      <td>0.033829</td>\n",
       "      <td>0.061498</td>\n",
       "      <td>0.048056</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009597</td>\n",
       "      <td>0.026770</td>\n",
       "      <td>-0.025910</td>\n",
       "      <td>-0.003175</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025926</td>\n",
       "      <td>0.050011</td>\n",
       "      <td>0.095451</td>\n",
       "      <td>0.075798</td>\n",
       "      <td>0.085378</td>\n",
       "      <td>0.047979</td>\n",
       "      <td>0.045498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001671</td>\n",
       "      <td>-0.006513</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.141181</td>\n",
       "      <td>0.191146</td>\n",
       "      <td>0.086680</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>0.060698</td>\n",
       "      <td>0.130613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008712</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>-0.003925</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163584</td>\n",
       "      <td>0.263132</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>-0.040968</td>\n",
       "      <td>0.037763</td>\n",
       "      <td>0.201152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023902</td>\n",
       "      <td>-0.037983</td>\n",
       "      <td>-0.006581</td>\n",
       "      <td>-0.032307</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150507</td>\n",
       "      <td>0.263743</td>\n",
       "      <td>-0.069921</td>\n",
       "      <td>0.063823</td>\n",
       "      <td>-0.024416</td>\n",
       "      <td>0.050875</td>\n",
       "      <td>0.190206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.026404</td>\n",
       "      <td>0.034336</td>\n",
       "      <td>0.036422</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mics12_0  mics12_1  mics12_2  mics12_3  mics12_4  mics12_5  mics12_6  ...  \\\n",
       "0  0.016540  0.019380  0.065406  0.033829  0.061498  0.048056  0.010450  ...   \n",
       "1  0.025926  0.050011  0.095451  0.075798  0.085378  0.047979  0.045498  ...   \n",
       "2  0.141181  0.191146  0.086680  0.026219  0.016993  0.060698  0.130613  ...   \n",
       "3  0.163584  0.263132 -0.068415  0.005264 -0.040968  0.037763  0.201152  ...   \n",
       "4  0.150507  0.263743 -0.069921  0.063823 -0.024416  0.050875  0.190206  ...   \n",
       "\n",
       "   mics12_17  mics12_18  mics12_19  mics12_20  dist   room  label  \n",
       "0  -0.009597   0.026770  -0.025910  -0.003175   100  large      0  \n",
       "1  -0.001671  -0.006513   0.006247   0.014060   100  large      0  \n",
       "2  -0.008712   0.030914   0.038090  -0.003925   100  large      0  \n",
       "3  -0.023902  -0.037983  -0.006581  -0.032307   100  large      0  \n",
       "4   0.008882   0.026404   0.034336   0.036422   100  large      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_dataframe('train', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "df_validation = create_dataframe('validation', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "df_test = create_dataframe('test', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "\n",
    "df_train.to_csv('../training_data/azimuth_train_dataset.csv')\n",
    "df_validation.to_csv('../training_data/azimuth_validation_dataset.csv')\n",
    "df_test.to_csv('../training_data/azimuth_test_dataset.csv')\n",
    "print('Subsets csv generated!')\n",
    "\n",
    "# Create numpy arrays with observations and one-hot labels\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "pd.set_option('display.max_columns', 15)\n",
    "df_train.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
