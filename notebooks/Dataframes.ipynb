{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate .csv files for CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import rc\n",
    "\n",
    "import pyroomacoustics as pra\n",
    "from pyroomacoustics.utilities import normalize\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Label resolution of angles\n",
    "RESOLUTION = 50\n",
    "\n",
    "# Number of samples to include while creating one ML feature\n",
    "SAMPLES = 2048\n",
    "\n",
    "# Determines the overlap of samples between consecutive features\n",
    "STEP = 1024\n",
    "\n",
    "# Training rooms dimensions\n",
    "ROOMS = {\n",
    "    'small' : np.array([4, 4, 3]),\n",
    "    'medium' : np.array([6, 6, 3]),\n",
    "    'large' : np.array([8, 8, 3])\n",
    "}\n",
    "\n",
    "# Testing rooms dimensions\n",
    "TEST_ROOMS = {\n",
    "    'small' : np.array([5, 5, 2]),\n",
    "    'medium' : np.array([7, 7, 2]),\n",
    "    'large' : np.array([9, 9, 2])\n",
    "}\n",
    "\n",
    "AUDIO_PATH = 'C:\\\\Users\\\\Alex\\\\source\\\\repos\\\\sound-localization\\\\data'\n",
    "\n",
    "# Number of microphones\n",
    "MICS_NUMBER = 2\n",
    "MIC_COMBS = len(list(combinations(range(MICS_NUMBER), 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcc_phat(x_1, x_2, FS=16000, interp=1):    \n",
    "    n = len(x_1) + len(x_2) - 1\n",
    "    n += 1 if n % 2 else 0\n",
    "    \n",
    "    # Fourier transforms of the two signals\n",
    "    X_1 = np.fft.rfft(x_1, n=n)\n",
    "    X_2 = np.fft.rfft(x_2, n=n)\n",
    "    \n",
    "    # Normalize by the magnitude of FFT - because PHAT\n",
    "    np.divide(X_1, np.abs(X_1), X_1, where=np.abs(X_1) != 0)\n",
    "    np.divide(X_2, np.abs(X_2), X_2, where=np.abs(X_2) != 0)\n",
    "    \n",
    "    # GCC-PHAT = [X_1(f)X_2*(f)] / |X_1(f)X_2*(f)|\n",
    "    # See http://www.xavieranguera.com/phdthesis/node92.html for reference\n",
    "    CC = X_1 * np.conj(X_2)\n",
    "    cc = np.fft.irfft(CC, n=n * interp)\n",
    "        \n",
    "    # Maximum delay between a pair of microphones,\n",
    "    # expressed in a number of samples.\n",
    "    # 0.09 m is the mic array diameter and \n",
    "    # 340 m/s is assumed to be the speed of sound.\n",
    "    max_len = math.ceil(0.09 / 340 * FS * interp)\n",
    "    \n",
    "    # Trim the cc vector to only include a \n",
    "    # small number of samples around the origin\n",
    "    cc = np.concatenate((cc[-max_len:], cc[:max_len+1]))\n",
    "    \n",
    "    # Return the cross correlation\n",
    "    return cc\n",
    "\n",
    "\n",
    "def one_hot_encode(encoder, y_train, y_test):    \n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "    \n",
    "    # One-hot encode training and testing labels\n",
    "    enc = encoder.fit(y_train)\n",
    "    y_train = enc.transform(y_train)\n",
    "    y_test = enc.transform(y_test)\n",
    "    \n",
    "    return y_train, y_test\n",
    "\n",
    "\n",
    "def compute_gcc_matrix(observation, fs, interp=1):    \n",
    "    mic_pairs = combinations(range(MICS_NUMBER), r=2)\n",
    "\n",
    "    # Initialize a transformed observation, that will be populated with GCC vectors\n",
    "    # of the observation\n",
    "    transformed_observation = []\n",
    "\n",
    "    # Compute GCC for every pair of microphones\n",
    "    for mic_1, mic_2 in mic_pairs:\n",
    "        x_1 = observation[:, mic_1]\n",
    "        x_2 = observation[:, mic_2]\n",
    "\n",
    "        gcc = gcc_phat(x_1, x_2, FS=fs, interp=interp)\n",
    "\n",
    "        # Add the GCC vector to the GCC matrix\n",
    "        transformed_observation.append(gcc)    \n",
    "        \n",
    "    return transformed_observation\n",
    "\n",
    "\n",
    "\n",
    "def create_observations(wav_signals, fs, label, samples=1, step=1, resolution=RESOLUTION, interp=1):\n",
    "    # Lists of observations and labels that will be populated\n",
    "    X = []\n",
    "    y = []\n",
    "    rounded_label = round(label / resolution) * resolution\n",
    "    if rounded_label == 360: rounded_label = 0\n",
    "    \n",
    "    # Loop through the signal frame and take subframes\n",
    "    for i in range(0, len(wav_signals) - samples + 1, step):\n",
    "        y.append(rounded_label)\n",
    "        \n",
    "        # Extract the observation from subframe\n",
    "        observation = np.array(wav_signals[i : i + samples])\n",
    "              \n",
    "        # Transform observation into a GCC matrix\n",
    "        transformed_observation = compute_gcc_matrix(observation, fs, interp=interp)\n",
    "            \n",
    "        X.append(transformed_observation)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def create_dataframe(subset, samples=20, step=5, resolution=RESOLUTION, interp=1):\n",
    "    dataframes = []\n",
    "    files = [f for f in os.listdir(AUDIO_PATH) if os.path.isfile(os.path.join(AUDIO_PATH, f))]\n",
    "\n",
    "    # Loop through all WAVs\n",
    "    for i, file in enumerate(files):\n",
    "        if file[-3:] != 'wav':\n",
    "            continue\n",
    "    \n",
    "        print(f'{subset} file {i+1}/{len(files)}', end='\\r')\n",
    "        path = os.path.join(AUDIO_PATH, file)\n",
    "        fs, wav_signals = wavfile.read(path)\n",
    "\n",
    "        label = int(file.split('_')[2])\n",
    "\n",
    "        # Create observations from a given WAV file\n",
    "        X_temp, y_temp = create_observations(wav_signals, fs, label, samples, step, resolution, interp=interp)\n",
    "\n",
    "        cols = [\n",
    "                f'mics{mic_1+1}{mic_2+1}_{i}' \n",
    "                    for mic_1, mic_2 in combinations(range(MICS_NUMBER), r=2) \n",
    "                        for i in range(np.shape(X_temp)[2])\n",
    "            ]\n",
    "\n",
    "        df = pd.DataFrame(data=np.reshape(X_temp, (len(X_temp), -1)), columns=cols)\n",
    "        dist = int(file.split('_')[4])\n",
    "        room = file.split('_')[6]\n",
    "        df['dist'], df['room'] = dist, room\n",
    "            \n",
    "        # Add label column\n",
    "        df['label'] = y_temp\n",
    "        dataframes.append(df)\n",
    "        \n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "def create_whole_dataset(df_train, df_test, encoder, room=None, dist=None):\n",
    "    \"\"\"\n",
    "    Creates an entire dataset by extracting values from train and tests dataframes.\n",
    "    One-hot encodes the labels before returning.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Can filter testing entries to only check performance\n",
    "    # for given conditions\n",
    "    if room:\n",
    "        df_test = df_test[df_test.room == room]\n",
    "    if dist:\n",
    "        df_test = df_test[df_test.dist == dist]\n",
    "    \n",
    "    # Create train/test observations\n",
    "    X_train = df_train.drop(columns=['dist', 'room', 'label']).values.reshape(\n",
    "        len(df_train), MIC_COMBS, -1)\n",
    "    X_test = df_test.drop(columns=['dist', 'room', 'label']).values.reshape(\n",
    "        len(df_test), MIC_COMBS, -1)\n",
    "    \n",
    "    # Create train/test labels\n",
    "    y_train, y_test = one_hot_encode(\n",
    "        encoder, df_train['label'].values, df_test['label'].values)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataframes for Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train file 96/96\n",
      "test file 96/96\n",
      "Subsets csv generated!\n",
      "(1416, 1, 11) (1416, 1, 11) (1416, 8) (1416, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mics12_0</th>\n",
       "      <th>mics12_1</th>\n",
       "      <th>mics12_2</th>\n",
       "      <th>mics12_3</th>\n",
       "      <th>mics12_4</th>\n",
       "      <th>mics12_5</th>\n",
       "      <th>mics12_6</th>\n",
       "      <th>mics12_7</th>\n",
       "      <th>mics12_8</th>\n",
       "      <th>mics12_9</th>\n",
       "      <th>mics12_10</th>\n",
       "      <th>dist</th>\n",
       "      <th>room</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.025136</td>\n",
       "      <td>0.020385</td>\n",
       "      <td>-0.024802</td>\n",
       "      <td>0.048243</td>\n",
       "      <td>-0.017659</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>-0.015431</td>\n",
       "      <td>-0.002458</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.017754</td>\n",
       "      <td>0.014812</td>\n",
       "      <td>-0.007982</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>-0.013178</td>\n",
       "      <td>0.013935</td>\n",
       "      <td>0.006427</td>\n",
       "      <td>0.026576</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>-0.013343</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.016788</td>\n",
       "      <td>0.015287</td>\n",
       "      <td>-0.023257</td>\n",
       "      <td>0.039458</td>\n",
       "      <td>-0.020512</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>-0.014571</td>\n",
       "      <td>0.018260</td>\n",
       "      <td>-0.004904</td>\n",
       "      <td>-0.009506</td>\n",
       "      <td>-0.007211</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.005019</td>\n",
       "      <td>0.018142</td>\n",
       "      <td>-0.019895</td>\n",
       "      <td>0.050879</td>\n",
       "      <td>-0.014223</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.015450</td>\n",
       "      <td>0.020179</td>\n",
       "      <td>-0.013012</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.005656</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.023272</td>\n",
       "      <td>0.011415</td>\n",
       "      <td>-0.016877</td>\n",
       "      <td>0.041161</td>\n",
       "      <td>-0.024162</td>\n",
       "      <td>-0.011187</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>0.027261</td>\n",
       "      <td>-0.019952</td>\n",
       "      <td>0.020208</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mics12_0  mics12_1  mics12_2  mics12_3  mics12_4  mics12_5  mics12_6  \\\n",
       "0 -0.025136  0.020385 -0.024802  0.048243 -0.017659  0.004446  0.002596   \n",
       "1 -0.017754  0.014812 -0.007982  0.029485 -0.013178  0.013935  0.006427   \n",
       "2 -0.016788  0.015287 -0.023257  0.039458 -0.020512  0.025355 -0.014571   \n",
       "3 -0.005019  0.018142 -0.019895  0.050879 -0.014223  0.007809  0.015450   \n",
       "4 -0.023272  0.011415 -0.016877  0.041161 -0.024162 -0.011187 -0.000976   \n",
       "\n",
       "   mics12_7  mics12_8  mics12_9  mics12_10  dist   room  label  \n",
       "0  0.005094 -0.015431 -0.002458  -0.001509   100  large      0  \n",
       "1  0.026576 -0.003771  0.008634  -0.013343   100  large      0  \n",
       "2  0.018260 -0.004904 -0.009506  -0.007211   100  large      0  \n",
       "3  0.020179 -0.013012  0.010354   0.005656   100  large      0  \n",
       "4  0.027261 -0.019952  0.020208   0.000826   100  large      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_dataframe('train', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "df_test = create_dataframe('test', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "\n",
    "df_train.to_csv('../training_data/azimuth_train_dataset.csv')\n",
    "df_test.to_csv('../training_data/azimuth_test_dataset.csv')\n",
    "print('Subsets csv generated!')\n",
    "\n",
    "# Create numpy arrays with observations and one-hot labels\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "pd.set_option('display.max_columns', 15)\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../training_data/azimuth_train_dataset.csv', index_col=[0])\n",
    "df_test = pd.read_csv('../training_data/azimuth_test_dataset.csv', index_col=[0])\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "encoder.fit([[label] for label in df_train['label']])\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
